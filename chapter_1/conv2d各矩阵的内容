import tensorflow as tf
import cv2
import numpy as np

img = cv2.imread('lena.png')  # 【74  111  193】
cv2.imshow("lena",img)
img = np.array(img,dtype=np.float32)  # 【74.  111.   193.】
print(img.shape)

"""
tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)
第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一
第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维
第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4
第四个参数padding：string类型的量，只能是"SAME","VALID"其中之一，这个值决定了不同的卷积方式（当其为‘SAME’时，表示卷积核可以停留在图像边缘）
第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true
结果返回一个Tensor，这个输出，就是我们常说的feature map，shape仍然是[batch, height, width, channels]这种形式。
"""
x_image = tf.reshape(img,[1,512,512,3])   # 当输入图像的尺寸小于512*512时会报错
filter = tf.Variable(tf.ones([7,7,3,1]))
init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    res = tf.nn.conv2d(x_image,filter,strides=[1,2,2,1],padding='SAME')
    rest = sess.run(tf.reshape(res,[256,256]))  # 此处必须用sess.run否则，rest与res基本相同
    cv2.imshow("rest",rest.astype('uint8'))  # 此处必须添加.astype('uint8')，否则cv2.imshow会报错

    res_img = sess.run(tf.reshape(res,[256,256]))/128+1
    cv2.imshow("lena",res_img.astype('uint8'))
    cv2.waitKey()
    
    
